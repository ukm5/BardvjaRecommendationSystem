{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing this paper now: ./../papers_train/final report don.pdf\n",
      "Parsing this paper now: ./../papers_train/Chevillard18-A.multifractal.model.for.the.velocity.gradient.dynamics.in.turbulent.flows.pdf\n",
      "Parsing this paper now: ./../papers_train/Chun turbulent coagulation page proofs.pdf\n",
      "Parsing this paper now: ./../papers_train/1908.09081.pdf\n",
      "Parsing this paper now: ./../papers_train/HIPPSTR.pdf\n",
      "Parsing this paper now: ./../papers_train/controlling_rotation_and_migration_of_rings_in_a_simple_shear_flow_through_geometric_modifications.pdf\n",
      "Parsing this paper now: ./../papers_train/94-abstract1.pdf\n",
      "Parsing this paper now: ./../papers_train/5849.full.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing this paper now: ./../papers_train/p1.pdf\n",
      "Parsing this paper now: ./../papers_train/p2.pdf\n",
      "Parsing this paper now: ./../papers_train/machine_learning_the_kinematics_of_spherical_particles_in_fluid_flows.pdf\n",
      "Parsing this paper now: ./../papers_train/p3.pdf\n",
      "Parsing this paper now: ./../papers_train/ARFM97-Sreenivasan.Antonia.Phenomenology.of.small-scale.turbulence.pdf\n",
      "Error: While trying to combine title and text there is issue at this file: ./../papers_train/ARFM97-Sreenivasan.Antonia.Phenomenology.of.small-scale.turbulence.pdf\n",
      "Parsing this paper now: ./../papers_train/p7.pdf\n",
      "Parsing this paper now: ./../papers_train/p6.pdf\n",
      "Parsing this paper now: ./../papers_train/Uday_thesis_July3.pdf\n",
      "Parsing this paper now: ./../papers_train/p4.pdf\n",
      "Parsing this paper now: ./../papers_train/The effect of Reynolds number on inertial particle dynamics in isotropic turbulence. Part 1. Simulations without gravitational effects.pdf\n",
      "Parsing this paper now: ./../papers_train/p5.pdf\n",
      "Parsing this paper now: ./../papers_train/voth annual review of rod rotation in turbulence.pdf\n",
      "Parsing this paper now: ./../papers_train/Collision turbulence efficiency JFM ver 2019 ver2.pdf\n",
      "Parsing this paper now: ./../papers_train/Good et al. settling regimes JFM.pdf\n",
      "Parsing this paper now: ./../papers_train/DandelionFlight.pdf\n",
      "Parsing this paper now: ./../papers_train/Fibre_Johnson_Dhanasekaran_Donald_Koch_JFM_January_2019.pdf\n",
      "Parsing this paper now: ./../papers_train/Turbulent coagulation of colloidal particles.pdf\n",
      "Error: While trying to combine title and text there is issue at this file: ./../papers_train/Turbulent coagulation of colloidal particles.pdf\n",
      "Parsing this paper now: ./../papers_train/1910.02068.pdf\n",
      "Parsing this paper now: ./../papers_train/On the collision of drops in turbulent clouds.pdf\n",
      "Parsing this paper now: ./../papers_train/17544-75906-1-PB.pdf\n",
      "Parsing this paper now: ./../papers_train/SBT.pdf\n",
      "Finished Regex body\n",
      "Finished Regex title\n",
      "Finished adding title and body\n",
      "Finished turning into lowercase and wordninja\n",
      "Finished stemming using porter\n",
      "\n",
      " Completed processing and training on the local papers! \n",
      "\n",
      "Parsing this paper now: ./../papers_train/final report don.pdf\n",
      "Parsing this paper now: ./../papers_train/Chevillard18-A.multifractal.model.for.the.velocity.gradient.dynamics.in.turbulent.flows.pdf\n",
      "Parsing this paper now: ./../papers_train/Chun turbulent coagulation page proofs.pdf\n",
      "Parsing this paper now: ./../papers_train/1908.09081.pdf\n",
      "Parsing this paper now: ./../papers_train/HIPPSTR.pdf\n",
      "Parsing this paper now: ./../papers_train/controlling_rotation_and_migration_of_rings_in_a_simple_shear_flow_through_geometric_modifications.pdf\n",
      "Parsing this paper now: ./../papers_train/94-abstract1.pdf\n",
      "Parsing this paper now: ./../papers_train/5849.full.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing this paper now: ./../papers_train/p1.pdf\n",
      "Parsing this paper now: ./../papers_train/p2.pdf\n",
      "Parsing this paper now: ./../papers_train/machine_learning_the_kinematics_of_spherical_particles_in_fluid_flows.pdf\n",
      "Parsing this paper now: ./../papers_train/p3.pdf\n",
      "Parsing this paper now: ./../papers_train/ARFM97-Sreenivasan.Antonia.Phenomenology.of.small-scale.turbulence.pdf\n",
      "Error: While trying to combine title and text there is issue at this file: ./../papers_train/ARFM97-Sreenivasan.Antonia.Phenomenology.of.small-scale.turbulence.pdf\n",
      "Parsing this paper now: ./../papers_train/p7.pdf\n",
      "Parsing this paper now: ./../papers_train/p6.pdf\n",
      "Parsing this paper now: ./../papers_train/Uday_thesis_July3.pdf\n",
      "Parsing this paper now: ./../papers_train/p4.pdf\n",
      "Parsing this paper now: ./../papers_train/The effect of Reynolds number on inertial particle dynamics in isotropic turbulence. Part 1. Simulations without gravitational effects.pdf\n",
      "Parsing this paper now: ./../papers_train/p5.pdf\n",
      "Parsing this paper now: ./../papers_train/voth annual review of rod rotation in turbulence.pdf\n",
      "Parsing this paper now: ./../papers_train/Collision turbulence efficiency JFM ver 2019 ver2.pdf\n",
      "Parsing this paper now: ./../papers_train/Good et al. settling regimes JFM.pdf\n",
      "Parsing this paper now: ./../papers_train/DandelionFlight.pdf\n",
      "Parsing this paper now: ./../papers_train/Fibre_Johnson_Dhanasekaran_Donald_Koch_JFM_January_2019.pdf\n",
      "Parsing this paper now: ./../papers_train/Turbulent coagulation of colloidal particles.pdf\n",
      "Error: While trying to combine title and text there is issue at this file: ./../papers_train/Turbulent coagulation of colloidal particles.pdf\n",
      "Parsing this paper now: ./../papers_train/1910.02068.pdf\n",
      "Parsing this paper now: ./../papers_train/On the collision of drops in turbulent clouds.pdf\n",
      "Parsing this paper now: ./../papers_train/17544-75906-1-PB.pdf\n",
      "Parsing this paper now: ./../papers_train/SBT.pdf\n",
      "Finished Regex body\n",
      "Finished Regex title\n",
      "Finished adding title and body\n",
      "Finished turning into lowercase and wordninja\n",
      "Finished stemming using porter\n",
      "\n",
      " Completed processing and training on the local papers! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Creating dataframe from pdfs\n",
    "\n",
    "import pdf_reader as pdfr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "from global_params import path_to_training_data, path_to_papers_train, path_to_trained_models\n",
    "\n",
    "def pypdf2_parser(path_to_pdf):\n",
    "    import PyPDF2\n",
    "    pdf_contents = {}\n",
    "    pdf_reader = PyPDF2.PdfFileReader(path_to_pdf)\n",
    "    pdf_contents['total_pages'] = pdf_reader.numPages\n",
    "    pdf_info = pdf_reader.getDocumentInfo()\n",
    "    pdf_contents['author'] = pdf_info.author\n",
    "    pdf_contents['title'] = str(pdf_info.title).lower()\n",
    "    pdf_contents['creator'] = pdf_info.creator\n",
    "    try:\n",
    "        pdf_contents['subject'] = pdf_info['/Subject'].split(' ')[0:-1]\n",
    "    except:\n",
    "        pdf_contents['subject'] = 'Unknown'\n",
    "    try:\n",
    "        pdf_contents['complete_pdf'] = pdf_contents['title'] + ' '.join([pdf_reader.getPage(i).extractText() for i in range(pdf_contents['total_pages'])])\n",
    "    except:\n",
    "        print(f\"Error: While trying to combine title and text there is issue at this file: {path_to_pdf}\")\n",
    "    return pdf_contents\n",
    "\n",
    "def make_training_dataframe(path_to_training_papers):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    train_data = {}\n",
    "    for idx, filename in enumerate(os.listdir(path_to_training_papers)):\n",
    "        if filename != '.DS_Store':\n",
    "            path_to_pdf = path_to_training_papers+filename\n",
    "            print(f\"Parsing this paper now: {path_to_pdf}\")\n",
    "            train_data[idx] = pypdf2_parser(path_to_pdf)\n",
    "\n",
    "    df = pd.DataFrame(train_data.values())\n",
    "    df.dropna(subset=['complete_pdf','title'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def pre_processing_pdf_text(df):\n",
    "    import pandas as pd\n",
    "    import wordninja\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    import regex as re\n",
    "\n",
    "    porter = PorterStemmer()\n",
    "\n",
    "    try:\n",
    "        df['complete_pdf'] = df['complete_pdf'].map(lambda x: re.sub('\\d+',\"\",x))\n",
    "        print(\"Finished Regex body\")\n",
    "        df['title'] = df['title'].map(lambda x: re.sub('\\d+',\"\",x))\n",
    "        print(\"Finished Regex title\")\n",
    "        df['complete_pdf'] = df['complete_pdf']*2 + ' ' + (df['title']+' ')*10\n",
    "        print(\"Finished adding title and body\")\n",
    "        df['complete_pdf'] = df['complete_pdf'].map(lambda x: wordninja.split(x.lower()))\n",
    "        print(\"Finished turning into lowercase and wordninja\")\n",
    "        df['complete_pdf'] = df['complete_pdf'].map(lambda x: ' '.join(list(map(porter.stem, x))))\n",
    "        print(\"Finished stemming using porter\")\n",
    "    except:\n",
    "        print(\"Error: Unable to pre-process this file: \")\n",
    "    return df\n",
    "\n",
    "def transform_abstracts_to_vectors(df, custom_stop_words=['a']):\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "    from sklearn.preprocessing import StandardScaler, normalize\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.decomposition import PCA\n",
    "    from scipy import sparse\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    import string\n",
    "    import joblib\n",
    "    \n",
    "    X = df['complete_pdf']\n",
    "    porter = PorterStemmer()\n",
    "    stop_words_english = list(map(porter.stem, ENGLISH_STOP_WORDS))\n",
    "    custom_stop_words = list(map(porter.stem, custom_stop_words))\n",
    "    stop_words_english += custom_stop_words\n",
    "    \n",
    "    chars = [c for c in string.ascii_lowercase]\n",
    "    stop_words_english += chars\n",
    "    for i in chars:\n",
    "        for j in chars:\n",
    "            stop_words_english.append(i+j)\n",
    "\n",
    "    try:\n",
    "        joblib.dump(stop_words_english, f'{path_to_trained_models}stop_words_english')\n",
    "    except:\n",
    "        print(\"Raised error trying to write stop_words_english!\")\n",
    "    \n",
    "    cvec = CountVectorizer(max_features=500, stop_words=stop_words_english, min_df=5, max_df=0.9)\n",
    "    tvec = TfidfVectorizer(max_features=500, stop_words=stop_words_english, min_df=5, max_df=0.9)\n",
    "\n",
    "    X_vec = cvec.fit_transform(X)\n",
    "    X_vec2 = tvec.fit_transform(X)   \n",
    "    joblib.dump(cvec.vocabulary_, f'{path_to_trained_models}cvec_vocabulary')\n",
    "    # Save the Vectorizer models for later\n",
    "    joblib.dump(cvec, f'{path_to_trained_models}count_vectorizer.sav')\n",
    "    joblib.dump(tvec, f'{path_to_trained_models}tfidf_vectorizer.sav')\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_vec_ss = ss.fit_transform(X_vec.toarray())\n",
    "    # Save the StandardScaler for later\n",
    "    joblib.dump(ss, f'{path_to_trained_models}standard_scaler.sav')\n",
    "    \n",
    "    k_cluster = KMeans(n_clusters=3, random_state=42, n_jobs=-1)\n",
    "    k_cluster.fit(X_vec_ss)\n",
    "    # Save the KMeans cluster for later\n",
    "    joblib.dump(k_cluster, f'{path_to_trained_models}kmeans_cluster.sav')\n",
    "    \n",
    "    df['cluster_label'] = k_cluster.predict(X_vec_ss)\n",
    "    X_vec = np.append(X_vec.toarray(),df['cluster_label'].values.reshape(-1,1), axis=1)\n",
    "    X_normal = normalize(sparse.csr_matrix(X_vec)).toarray()\n",
    "    \n",
    "    return X_normal\n",
    "\n",
    "if not os.path.isdir(f'{path_to_papers_train}'):\n",
    "    print(f\"Please ensure the directory with pdfs to be trained on is at {path_to_papers_train}\")\n",
    "    os.mkdir(f'{path_to_papers_train}')\n",
    "\n",
    "if not os.path.isdir(f'{path_to_training_data}'):\n",
    "    print(f\"Creating folder to keep training data at {path_to_training_data}\")\n",
    "    os.mkdir(f'{path_to_training_data}')\n",
    "\n",
    "if not os.path.isdir(f'{path_to_trained_models}'):\n",
    "    print(f\"Creating folder to keep trained models at {path_to_trained_models}\")\n",
    "    os.mkdir(f'{path_to_trained_models}/')\n",
    "\n",
    "\n",
    "df = make_training_dataframe(f'{path_to_papers_train}')\n",
    "\n",
    "df = pre_processing_pdf_text(df)\n",
    "\n",
    "df.to_csv(f'{path_to_training_data}local_papers.csv', index=False)\n",
    "\n",
    "df = pd.read_csv(f'{path_to_training_data}local_papers.csv')\n",
    "\n",
    "### Developing model\n",
    "\n",
    "# Added these using some subject-matter expertise being in research\n",
    "# People may modify it to their needs if required\n",
    "custom_stop_words = ['fig','figure','table','abstract','summary','method','research','publication','published','test',\n",
    "                    'effect','different','mean','sum','variance','variety','analysis','given','provided','lead'\n",
    "                    'large','small','low','pro','pre','similar','report','length','width','high','section','include',\n",
    "                    'close','approximation','new','old','non','etc','occur','represent','characeristic','characterization'\n",
    "                    'character','problem','presence','suggestion','enhance']\n",
    "\n",
    "Z = transform_abstracts_to_vectors(df)\n",
    "Z_sparse = sparse.csr_matrix(Z)\n",
    "sparse.save_npz(f'{path_to_training_data}normalized_train_vectors.npz', matrix=Z_sparse)\n",
    "\n",
    "print('\\n Completed processing and training on the local papers! \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
